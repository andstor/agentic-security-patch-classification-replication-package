{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6d81e1-2f07-4298-8c07-61a9e398c3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2debeaf5-66d3-491a-9db1-bc741180b6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /cluster/home/andstorh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "from nltk import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fe1d38-6e0f-4d82-a079-b772082a979c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../../../data/baselines/PatchFinder'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60e451b3-e48c-42f3-b8f4-b61dac2e84ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecf244d464ed4cb4afab9f5e704f858d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "521d68d4c10d4943ac1672622646c275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/540 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67b7edb62b4e4116a91b28efb91dc45d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/793 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af7a41af9594421913330f8dc2d587a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c63c40036fa44bc86adff721e0f288a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/540 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d47a4dfd3ee94ae5bf0949216f854449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/793 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e79227836b4d44b599230f207e504e2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f56712fc7b544d518fa095c3df1f5128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/540 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "363c9ff6b22f43ad91220d6be75ce9f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/793 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31821af712b2418380f9a9d167859e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/182 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6f95e5b4bc34a4191cff8285e63afcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/213 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "824187f5d7b44ef4a6222499c5cc0357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_cve = load_dataset('fals3/cvevc_cve')\n",
    "ds_patches = load_dataset('fals3/cvcvc_commits', \"patches\")\n",
    "ds_nonpatches = load_dataset('fals3/cvcvc_commits', \"non_patches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e7e5827-6e13-4cea-8e0b-f3e3073505db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def convert_to_unified_0(diff: str) -> str:\n",
    "    \"\"\"\n",
    "    Takes a git diff string and returns a version equivalent to `git diff --unified=0`.\n",
    "    \"\"\"\n",
    "    output_lines = []\n",
    "    diff_lines = diff.splitlines()\n",
    "    \n",
    "    inside_diff = False\n",
    "    \n",
    "    for line in diff_lines:\n",
    "        if line.startswith(\"diff --git\") or line.startswith(\"index\") or line.startswith(\"---\") or line.startswith(\"+++\"):\n",
    "            output_lines.append(line)\n",
    "        elif line.startswith(\"@@\"):\n",
    "            inside_diff = True\n",
    "            # Extract hunk header and modify it to show 0 lines of context\n",
    "            match = re.match(r\"@@ -(\\d+),?(\\d*) \\+(\\d+),?(\\d*) @@\", line)\n",
    "            if match:\n",
    "                old_start, old_count, new_start, new_count = match.groups()\n",
    "                old_count = int(old_count) if old_count else 1\n",
    "                new_count = int(new_count) if new_count else 1\n",
    "                output_lines.append(f\"@@ -{old_start},0 +{new_start},0 @@\")\n",
    "            else:\n",
    "                output_lines.append(line)\n",
    "        elif inside_diff:\n",
    "            if line.startswith(\"+\") or line.startswith(\"-\"):\n",
    "                output_lines.append(line)\n",
    "        else:\n",
    "            output_lines.append(line)\n",
    "    \n",
    "    return \"\\n\".join(output_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af15f6f1-c684-4479-8b96-1b1967faae20",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def format_git_show_minimal(git_show_string):\n",
    "    \"\"\"\n",
    "    Robustly extracts diff content starting from the first '@@' line for each file, including the 'diff --git' line.\n",
    "\n",
    "    Args:\n",
    "        git_show_string: The git show diff string with potentially multiple file diffs.\n",
    "\n",
    "    Returns:\n",
    "        The extracted diff content, or an empty string if no diff is found.\n",
    "    \"\"\"\n",
    "    lines = git_show_string.splitlines()\n",
    "    result_diffs = []\n",
    "    current_diff = []\n",
    "    at_at_found = False\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith(\"diff --git\"):\n",
    "            if current_diff:  # Store the previous diff if any\n",
    "                result_diffs.append(\"\\n\".join(current_diff))\n",
    "            current_diff = [line]  # Start a new diff\n",
    "            at_at_found = False\n",
    "        elif current_diff:\n",
    "            if line.startswith(\"@@\"):\n",
    "                at_at_found = True\n",
    "                current_diff.append(line)\n",
    "            elif at_at_found:\n",
    "                current_diff.append(line)\n",
    "\n",
    "    if current_diff:  # Store the last diff\n",
    "        result_diffs.append(\"\\n\".join(current_diff))\n",
    "\n",
    "    return \"\\n\".join(result_diffs).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b989602-9613-4045-8f4d-91392b12f879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_old(text: str) -> list:\n",
    "    text = text.lower()\n",
    "    lines = text.splitlines()\n",
    "    \n",
    "    processed_text = []\n",
    "    \n",
    "    for line in lines:\n",
    "        # Split the line into segments by spaces and keep the spaces\n",
    "        segments = re.split(r'(\\s+)', line)\n",
    "        \n",
    "        # Tokenize the segments and join them directly without intermediate lists\n",
    "        processed_line = \"\".join(\n",
    "            \" \".join(nltk.wordpunct_tokenize(segment)) if not segment.isspace() else segment\n",
    "            for segment in segments\n",
    "        )\n",
    "        \n",
    "        # Add the processed line to the result\n",
    "        processed_text.append(processed_line)\n",
    "    \n",
    "    # Join all processed lines with newlines\n",
    "    return \"\\n\".join(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17efb4f9-29a7-4e19-96a6-27240404a5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cpus = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a9cbec-fd67-4e28-b9ed-0b121dfc34b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_cve = ds_cve.map(lambda x: {\"desc_token\": ' '.join(word_tokenize(x[\"desc\"]))}, batched=False, num_proc=num_cpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29723a0-bce4-4022-9894-ca30bb5a7d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove binaries\n",
    "ds_patches = ds_patches.filter(lambda x: len(x['diff']) <= 500000, batched=False, num_proc=num_cpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dee635-b36e-46d9-a6aa-4b864be7a1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1c8635b7e0144eea1a544ea90124c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=10):   0%|          | 0/11504 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ec23e6760cc42888f92b3b7e85e3b3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=10):   0%|          | 0/1433 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adcd2cd2fd604fe6b1d198db0d515cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=10):   0%|          | 0/1442 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_patches = ds_patches.map(lambda x: {\"diff_token\": \n",
    "                                            ' '.join(word_tokenize(\n",
    "                                                ''.join(format_git_show_minimal(\n",
    "                                                    convert_to_unified_0(\n",
    "                                                       x[\"diff\"]\n",
    "                                                    )\n",
    "                                               ).splitlines(keepends=True)[:1000])\n",
    "                                           )),\n",
    "                                       \"msg_token\": ' '.join(word_tokenize(x[\"commit_message\"]))\n",
    "                                      }, batched=False, num_proc=num_cpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67708e11-c3e8-4cf3-adfe-55d5e3b644fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_patches = ds_patches.remove_columns([\"commit_message\", \"diff\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "430c8259-3318-460d-82cd-d9f3d3406bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove binaries\n",
    "ds_nonpatches = ds_nonpatches.filter(lambda x: len(x['diff']) <= 500000, batched=False, num_proc=num_cpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d3d13b-7861-4d0d-9801-fff6dbeb0e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2289202461454949b7b15151a387e8aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=10):   0%|          | 0/2226923 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_nonpatches = ds_nonpatches.map(lambda x: {\"diff_token\": \n",
    "                                                  ' '.join(word_tokenize(\n",
    "                                                      \"\".join(format_git_show_minimal(\n",
    "                                                          convert_to_unified_0(\n",
    "                                                             x[\"diff\"]\n",
    "                                                          )\n",
    "                                                     ).splitlines(keepends=True)[:1000])\n",
    "                                                 )),\n",
    "                                             \"msg_token\": ' '.join(word_tokenize(x[\"commit_message\"]))\n",
    "                                            }, batched=False, num_proc=num_cpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d83adc-c8e8-4c22-9a36-f7f7d4b58b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_nonpatches = ds_nonpatches.remove_columns([\"commit_message\", \"diff\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31045c3c-6de1-4a61-8deb-f35e20ccc360",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p \"tmp/tokenized\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d611d406-827f-4a71-9623-99886e27d7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_datasetdict_to_parquet(ds_dict, name: str, out_dir: str):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    for split_name, split_ds in ds_dict.items():\n",
    "        out_path = os.path.join(out_dir, f\"{name}_{split_name}.parquet\")\n",
    "        split_ds.to_parquet(out_path)\n",
    "        print(f\"✅ Saved: {out_path}\")\n",
    "\n",
    "# Call it for each dataset\n",
    "save_datasetdict_to_parquet(ds_cve, \"cve\", \"tmp/tokenized\")\n",
    "save_datasetdict_to_parquet(ds_patches, \"patches\", \"tmp/tokenized\")\n",
    "#save_datasetdict_to_parquet(ds_nonpatches, \"nonpatches\", \"tmp/tokenized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53be6bd2-24ae-48d0-abe9-23e76dd0dd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "\n",
    "for split, dataset in tqdm(ds_nonpatches.items(), total=len(ds_nonpatches), desc=\"Partitioning splits\"):\n",
    "    # Convert to Polars DataFrame\n",
    "    df = dataset.to_polars()\n",
    "    groups = df.group_by([\"owner\", \"repo\"])\n",
    "    num_groups = groups.len().shape[0]\n",
    "    \n",
    "    for name, data in tqdm(groups, total=num_groups):\n",
    "        safe_name = \"_\".join(name)\n",
    "        output_path = f\"tmp/owner_repo_groups/{split}\"\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "        data.write_parquet(os.path.join(output_path, f\"{safe_name}.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8326f711-d34b-41ee-83a1-e9fe834ee0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DONE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
